{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Plan: From Historical Analysis to Real-Time Flight Predictions\n",
        "\n",
        "This plan is broken down into the three parts you've outlined. Each part will be a section in the final Colab notebook, with clear instructions and code cells.\n",
        "\n",
        "# **Part I: Batch Processing of Historical Flight Data**\n",
        "\n",
        "Objective: To build a foundational understanding of data engineering and machine learning using a large, static dataset.\n",
        "\n",
        "Cell-by-Cell Plan:\n",
        "\n",
        "Setup and Authentication:\n",
        "\n",
        "Install necessary libraries (google-cloud-storage, google-cloud-bigquery, pandas, db-dtypes).\n",
        "\n",
        "Authenticate the user and configure the GCP project.\n",
        "\n",
        "Define all necessary variables (bucket names, dataset names, etc.).\n",
        "\n",
        "Data Acquisition (Downloading 2024 Flight Data):\n",
        "\n",
        "Provide a function that programmatically downloads the 2024 On-Time Performance data directly from the BTS.gov website. We will select a few months to keep the dataset manageable.\n",
        "\n",
        "The code will download the zipped CSV files and then unzip them.\n",
        "\n",
        "Move Data to GCS Bucket:\n",
        "\n",
        "Create a new GCS bucket.\n",
        "\n",
        "Upload the downloaded and unzipped CSV files to this bucket. This establishes our \"data lake.\"\n",
        "\n",
        "Load Data into a BigQuery Table:\n",
        "\n",
        "Create a new BigQuery dataset.\n",
        "\n",
        "Use a BigQuery Load Job to load all the CSV files from the GCS bucket into a single BigQuery table. We will use schema auto-detection.\n",
        "\n",
        "Data Cleaning and Feature Engineering in BigQuery:\n",
        "\n",
        "Run SQL queries to inspect the data, handle nulls, and create new features. A key feature will be creating a boolean label for logistic regression, such as is_arrival_delayed (TRUE if ARR_DELAY > 15 minutes).\n",
        "\n",
        "Build a Linear Regression Model:\n",
        "\n",
        "Use BigQuery ML to create a linear regression model to predict a continuous variable.\n",
        "\n",
        "Goal: Predict ARR_DELAY based on features like DEP_DELAY, CARRIER, DISTANCE, and DAY_OF_WEEK.\n",
        "\n",
        "Include cells to create, evaluate, and make predictions with the model.\n",
        "\n",
        "Build a Logistic Regression Model:\n",
        "\n",
        "Use BigQuery ML to create a logistic regression model for classification.\n",
        "\n",
        "Goal: Predict the is_arrival_delayed boolean label we created earlier.\n",
        "\n",
        "Include cells to create, evaluate (checking precision/recall), and make predictions.\n",
        "\n",
        "Build a K-Means Clustering Model:\n",
        "\n",
        "Use BigQuery ML to create a K-Means clustering model to segment the data.\n",
        "\n",
        "Goal: Group flights into clusters based on their characteristics (e.g., \"long-haul, often delayed,\" \"short-haul, on-time\").\n",
        "\n",
        "Include cells to create the model and analyze the resulting cluster centroids to understand their meaning.\n",
        "\n",
        "# **Part II: Micro-Batch Processing of \"Live\" Data**\n",
        "\n",
        "Objective: To simulate a streaming environment where new data arrives periodically and build a pipeline to process it.\n",
        "\n",
        "Cell-by-Cell Plan:\n",
        "\n",
        "Introduction to Streaming Concepts:\n",
        "\n",
        "Explain the difference between batch and streaming. Introduce the OpenSky Network API as our source for live flight data.\n",
        "\n",
        "Build a Cloud Function for Data Ingestion (GCS Trigger):\n",
        "\n",
        "Provide the Python code for a Google Cloud Function.\n",
        "\n",
        "Function's Job: This function will be triggered on a schedule (e.g., every 15 minutes using Cloud Scheduler). It will call the OpenSky Network API, fetch all current flight vectors, format the data as a JSON file, and save it to a new GCS bucket (our \"streaming landing zone\").\n",
        "\n",
        "Set up the Pub/Sub and BigQuery Streaming Infrastructure:\n",
        "\n",
        "Create a Pub/Sub topic that will receive notifications about new files.\n",
        "\n",
        "Configure the GCS bucket to send a message to this Pub/Sub topic every time a new file is created.\n",
        "\n",
        "Create a new BigQuery table to hold the streaming data.\n",
        "\n",
        "Build a Dataflow Pipeline (Pub/Sub to BigQuery):\n",
        "\n",
        "Provide the code for a second Cloud Function (or a Dataflow job) that is triggered by messages on the Pub/Sub topic.\n",
        "\n",
        "Function's Job: When triggered, it will read the new JSON file from GCS, parse it, and stream the data into the new BigQuery table.\n",
        "\n",
        "Build ML Models on the Streaming Data:\n",
        "\n",
        "Re-run the same BigQuery ML CREATE MODEL statements from Part I, but this time, train them on the new BigQuery table that is being populated with the streaming data. This demonstrates how models can be updated with fresh data.\n",
        "\n",
        "## **Part III: Real-Time Prediction**\n",
        "\n",
        "Objective: To build a true real-time pipeline that makes predictions on individual events as they happen.\n",
        "\n",
        "Cell-by-Cell Plan:\n",
        "\n",
        "Architecting for Real-Time:\n",
        "\n",
        "Explain why for true real-time, we want to bypass saving files to GCS and send data directly to a message queue.\n",
        "\n",
        "Build a Cloud Function for Direct Streaming (Pub/Sub):\n",
        "\n",
        "Provide the code for a new, optimized Cloud Function.\n",
        "\n",
        "Function's Job: This function will be triggered by a scheduler. It will fetch data from the OpenSky API and publish each flight's data as a separate message directly to a new Pub/Sub topic.\n",
        "\n",
        "Real-Time Prediction Pipeline:\n",
        "\n",
        "Provide the code for a final Cloud Function that acts as our real-time prediction engine.\n",
        "\n",
        "Function's Job: This function will be a subscriber to the Pub/Sub topic from the previous step. For each message (each flight) it receives, it will immediately call the ML.PREDICT function using the models developed in Part II.\n",
        "\n",
        "The prediction results (e.g., \"this flight is likely to be delayed\") can then be saved to a separate \"predictions\" table in BigQuery.\n",
        "\n",
        "Visualizing Real-Time Results:\n",
        "\n",
        "Include a final set of BigQuery queries that students can run to see the predictions populating the new table in near real-time."
      ],
      "metadata": {
        "id": "0qLMfIWGe_hF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MmN3sgbvy_w_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3489928-fd69-42b1-928a-4f10fd083b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticating your Google account...\n",
            "‚úÖ Authentication successful.\n",
            "‚ö†Ô∏è Could not automatically determine GCP Project ID.\n",
            "Please enter your GCP Project ID: mgmt-467-25259\n",
            "‚úÖ Using GCP Project: mgmt-467-25259\n"
          ]
        }
      ],
      "source": [
        "# @title ### Cell 1: Setup, Authentication, and Configuration (Corrected)\n",
        "# @markdown **Objective:** This cell imports all necessary Python libraries, authenticates your Google account to allow access to your GCP project, and sets up key configuration variables.\n",
        "\n",
        "# ---\n",
        "# **Libraries Explained:**\n",
        "# - `os`: For interacting with the operating system, like removing files.\n",
        "# - `subprocess`: Allows us to run shell commands like `gcloud`.\n",
        "# - `google.colab.auth`: A specific Colab library to handle authentication with your Google account.\n",
        "# ---\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from google.colab import auth\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"\n",
        "    Authenticates the user and configures the necessary GCP project.\n",
        "\n",
        "    This function handles the initial setup by authenticating the user's Google account\n",
        "    for use within the Colab environment. It then programmatically determines the\n",
        "    current GCP Project ID. If it cannot be determined automatically, it will prompt\n",
        "    the user to enter it manually.\n",
        "\n",
        "    Returns:\n",
        "        str: The Project ID.\n",
        "               Returns None if the project ID is not provided.\n",
        "    \"\"\"\n",
        "    print(\"Authenticating your Google account...\")\n",
        "    auth.authenticate_user()\n",
        "    print(\"‚úÖ Authentication successful.\")\n",
        "\n",
        "    project_id = \"\"\n",
        "    try:\n",
        "        project_id_process = subprocess.run(\n",
        "            [\"gcloud\", \"config\", \"get-value\", \"project\"],\n",
        "            capture_output=True, text=True, check=True\n",
        "        )\n",
        "        project_id = project_id_process.stdout.strip()\n",
        "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "        pass\n",
        "\n",
        "    if not project_id:\n",
        "        print(\"‚ö†Ô∏è Could not automatically determine GCP Project ID.\")\n",
        "        project_id = input(\"Please enter your GCP Project ID: \")\n",
        "\n",
        "    if not project_id:\n",
        "        print(\"üî¥ ERROR: Project ID is required to continue. Halting execution.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"‚úÖ Using GCP Project: {project_id}\")\n",
        "    return project_id\n",
        "\n",
        "# Run the setup function and store the variables.\n",
        "PROJECT_ID = setup_environment()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9233c1fc",
        "outputId": "3ac6fa04-130c-4459-fac6-9bcd05640d61"
      },
      "source": [
        "!pip install functions-framework google-cloud-pubsub\n",
        "\n",
        "import functions_framework\n",
        "from google.cloud import pubsub_v1\n",
        "import json\n",
        "import os\n",
        "import requests # Make sure requests is imported\n",
        "\n",
        "# OpenSky Network API configuration\n",
        "OPENSKY_USERNAME = os.environ.get(\"OPENSKY_USERNAME\")\n",
        "OPENSKY_PASSWORD = os.environ.get(\"OPENSKY_PASSWORD\")\n",
        "\n",
        "# --- User-defined Pub/Sub Topic and Project ID ---\n",
        "PUBSUB_TOPIC_NAME = \"live-data-stream\" # Updated to user's specified topic\n",
        "PROJECT_ID = os.environ.get(\"GCP_PROJECT\") # Cloud Functions automatically set this env var\n",
        "\n",
        "publisher = pubsub_v1.PublisherClient()\n",
        "topic_path = publisher.topic_path(PROJECT_ID, PUBSUB_TOPIC_NAME)\n",
        "\n",
        "@functions_framework.http\n",
        "def publish_flight_data(request):\n",
        "    \"\"\"\n",
        "    HTTP Cloud Function that fetches live flight data and publishes it to Pub/Sub.\n",
        "\n",
        "    This function fetches live flight data from the OpenSky Network API\n",
        "    and then publishes each flight record as a JSON message to a Pub/Sub topic.\n",
        "    It replaces a hypothetical direct BigQuery insertion with Pub/Sub publishing.\n",
        "    \"\"\"\n",
        "    if not PROJECT_ID or not PUBSUB_TOPIC_NAME:\n",
        "        print(\"Error: PROJECT_ID or PUBSUB_TOPIC_NAME not set.\")\n",
        "        return ('Configuration error', 500)\n",
        "\n",
        "    if not OPENSKY_USERNAME or not OPENSKY_PASSWORD:\n",
        "        print(\"Error: OPENSKY_USERNAME or OPENSKY_PASSWORD environment variables not set. Cannot fetch from OpenSky.\")\n",
        "        return ('Configuration error: OpenSky credentials missing', 500)\n",
        "\n",
        "    print(f\"Fetching flight data from OpenSky and publishing to {PUBSUB_TOPIC_NAME}...\")\n",
        "\n",
        "    flight_data_list = []\n",
        "    try:\n",
        "        # Actual OpenSky API call\n",
        "        response = requests.get(\n",
        "            f\"https://{OPENSKY_USERNAME}:{OPENSKY_PASSWORD}@opensky-network.org/api/states/all\",\n",
        "            timeout=30\n",
        "        )\n",
        "        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "        data = response.json()\n",
        "        raw_states = data.get(\"states\", [])\n",
        "\n",
        "        for state in raw_states:\n",
        "            # OpenSky state vector elements mapping:\n",
        "            # 0: icao24 (string) - Unique ICAO 24-bit address\n",
        "            # 1: callsign (string) - Callsign of the vehicle\n",
        "            # 2: origin_country (string) - Country name inferred by ICAO 24-bit address.\n",
        "            # 3: time_position (int) - Unix timestamp (seconds) for the last position update. Can be null.\n",
        "            # 5: longitude (float) - In decimal degrees (WGS-84)\n",
        "            # 6: latitude (float) - In decimal degrees (WGS-84)\n",
        "            # 9: velocity (float) - Velocity over ground in m/s\n",
        "            # 13: baro_altitude (float) - Barometric altitude in metres. Can be null.\n",
        "\n",
        "            # Filter for valid flight data with position\n",
        "            if state and state[5] is not None and state[6] is not None:\n",
        "                flight_record = {\n",
        "                    \"aircraft_id\": state[0],\n",
        "                    \"callsign\": state[1].strip() if state[1] else None, # Clean callsign\n",
        "                    \"origin_country\": state[2],\n",
        "                    \"timestamp\": state[3], # Unix timestamp\n",
        "                    \"longitude\": state[5],\n",
        "                    \"latitude\": state[6],\n",
        "                    \"velocity_m_s\": state[9],\n",
        "                    \"baro_altitude_m\": state[13] # Include altitude\n",
        "                }\n",
        "                flight_data_list.append(flight_record)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching OpenSky data: {e}\")\n",
        "        return (f'Failed to fetch flight data: {e}', 500)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during data fetching or parsing: {e}\")\n",
        "        return (f'Internal server error: {e}', 500)\n",
        "\n",
        "    if not flight_data_list:\n",
        "        print(\"No flight data received from OpenSky or no valid flights to process.\")\n",
        "        return ('No flight data to publish', 200)\n",
        "\n",
        "    published_messages = []\n",
        "    for flight_record in flight_data_list:\n",
        "        try:\n",
        "            # Data must be a bytestring\n",
        "            data_bytes = json.dumps(flight_record).encode(\"utf-8\")\n",
        "\n",
        "            # Publishes the message\n",
        "            future = publisher.publish(topic_path, data_bytes)\n",
        "            message_id = future.result()\n",
        "            published_messages.append(message_id)\n",
        "            print(f\"Published message for flight {flight_record.get('callsign', 'N/A')} ({flight_record.get('aircraft_id', 'N/A')}). ID: {message_id}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to publish message for flight {flight_record.get('callsign', 'N/A')}: {e}\")\n",
        "\n",
        "    print(f\"Successfully published {len(published_messages)} messages to {PUBSUB_TOPIC_NAME}.\")\n",
        "    return (f'Successfully published {len(published_messages)} messages.', 200)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: functions-framework in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: google-cloud-pubsub in /usr/local/lib/python3.12/dist-packages (2.33.0)\n",
            "Requirement already satisfied: flask<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from functions-framework) (3.1.2)\n",
            "Requirement already satisfied: click<9.0,>=7.0 in /usr/local/lib/python3.12/dist-packages (from functions-framework) (8.3.1)\n",
            "Requirement already satisfied: watchdog>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from functions-framework) (6.0.0)\n",
            "Requirement already satisfied: gunicorn>=22.0.0 in /usr/local/lib/python3.12/dist-packages (from functions-framework) (23.0.0)\n",
            "Requirement already satisfied: cloudevents<=1.12.0,>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from functions-framework) (1.12.0)\n",
            "Requirement already satisfied: Werkzeug<4.0.0,>=0.14 in /usr/local/lib/python3.12/dist-packages (from functions-framework) (3.1.3)\n",
            "Requirement already satisfied: starlette<1.0.0,>=0.37.0 in /usr/local/lib/python3.12/dist-packages (from functions-framework) (0.50.0)\n",
            "Requirement already satisfied: uvicorn<1.0.0,>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from functions-framework) (0.38.0)\n",
            "Requirement already satisfied: uvicorn-worker<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from functions-framework) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.51.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub) (1.76.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub) (2.38.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-pubsub) (2.28.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub) (5.29.5)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub) (0.14.3)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub) (1.71.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.27.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.27.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-pubsub) (1.37.0)\n",
            "Requirement already satisfied: deprecation<3.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from cloudevents<=1.12.0,>=1.12.0->functions-framework) (2.1.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask<4.0,>=2.0->functions-framework) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask<4.0,>=2.0->functions-framework) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask<4.0,>=2.0->functions-framework) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask<4.0,>=2.0->functions-framework) (3.0.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-pubsub) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-pubsub) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-pubsub) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-pubsub) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-pubsub) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio<2.0.0,>=1.51.3->google-cloud-pubsub) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gunicorn>=22.0.0->functions-framework) (25.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.27.0->google-cloud-pubsub) (0.58b0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<1.0.0,>=0.37.0->functions-framework) (4.11.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1.0.0,>=0.18.0->functions-framework) (0.16.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<1.0.0,>=0.37.0->functions-framework) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<1.0.0,>=0.37.0->functions-framework) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.27.0->google-cloud-pubsub) (3.23.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-pubsub) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-pubsub) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-pubsub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-pubsub) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7253f76f"
      },
      "source": [
        "### Deployment Instructions for the Pub/Sub Publisher Cloud Function\n",
        "\n",
        "This Python code, `publish_flight_data`, is designed to be deployed as a Google Cloud Function. It aligns with **Part III: Real-Time Prediction** of your project plan, specifically \"Build a Cloud Function for Direct Streaming (Pub/Sub)\".\n",
        "\n",
        "**To deploy this function, you would typically follow these steps:**\n",
        "\n",
        "1.  **Create a Pub/Sub Topic:** If you haven't already, create a Pub/Sub topic in your GCP project named `live-flight-data-stream` (or whatever you set `PUBSUB_TOPIC_NAME` to).\n",
        "    ```bash\n",
        "    gcloud pubsub topics create live-flight-data-stream\n",
        "    ```\n",
        "2.  **Save the Code:** Save the Python code above into a file named `main.py`.\n",
        "3.  **Define Dependencies:** Create a `requirements.txt` file in the same directory with the following content:\n",
        "    ```\n",
        "    functions-framework\n",
        "    google-cloud-pubsub\n",
        "    requests # If you integrate OpenSky API fetching\n",
        "    ```\n",
        "4.  **Deploy the Cloud Function:** Use the `gcloud functions deploy` command. You'll need to specify:\n",
        "    *   `--runtime python312` (or your preferred Python version)\n",
        "    *   `--trigger-http` (as it's an HTTP-triggered function, which can then be invoked by Cloud Scheduler)\n",
        "    *   `--entry-point publish_flight_data` (the name of the function to execute)\n",
        "    *   `--region` (e.g., `us-central1`)\n",
        "    *   `--allow-unauthenticated` (if you want to call it without authentication, common for scheduler triggers, but be mindful of security)\n",
        "    *   `--set-env-vars` for `OPENSKY_USERNAME` and `OPENSKY_PASSWORD` if you integrate the OpenSky API.\n",
        "\n",
        "    Example deployment command:\n",
        "    ```bash\n",
        "    gcloud functions deploy publish-flight-data-to-pubsub \\\n",
        "      --runtime python312 \\\n",
        "      --trigger-http \\\n",
        "      --entry-point publish_flight_data \\\n",
        "      --region us-central1 \\\n",
        "      --allow-unauthenticated # Or configure authentication for production\n",
        "      # --set-env-vars OPENSKY_USERNAME=your_username,OPENSKY_PASSWORD=your_password\n",
        "    ```\n",
        "\n",
        "5.  **Schedule the Function:** Create a Cloud Scheduler job to invoke this HTTP Cloud Function periodically (e.g., every 15 minutes), as outlined in your plan."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### Cell 6: Create BigQuery Dataset\n",
        "# @markdown **Objective:** This cell creates a new dataset in BigQuery to store our flight data. A dataset is a container for your tables, similar to a schema in a traditional database.\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.exceptions import Conflict\n",
        "\n",
        "# Initialize the BigQuery client\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# Define the name for your new BigQuery dataset\n",
        "BIGQUERY_DATASET = \"flights_data\"\n",
        "dataset_id = f\"{PROJECT_ID}.{BIGQUERY_DATASET}\"\n",
        "\n",
        "try:\n",
        "    # Create a Dataset object\n",
        "    dataset = bigquery.Dataset(dataset_id)\n",
        "    # Specify the location for the dataset\n",
        "    dataset.location = \"US\" # You can change this to your preferred location\n",
        "    # Make an API request to create the dataset\n",
        "    client.create_dataset(dataset, timeout=30)\n",
        "    print(f\"‚úÖ Successfully created dataset: {dataset_id}\")\n",
        "except Conflict:\n",
        "    print(f\"‚úÖ Dataset '{dataset_id}' already exists.\")\n",
        "except Exception as e:\n",
        "    print(f\"üî¥ An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "Gon0xv6UhWGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fdd649b-b672-4e82-d283-0e1486100928"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset 'mgmt-467-25259.flights_data' already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d6ef7c5",
        "outputId": "67cb8ccd-b16e-4c58-c867-62d46b1433eb"
      },
      "source": [
        "# @title ### Verify Streaming Data in BigQuery\n",
        "# @markdown **Objective:** Run a query to check if data is being ingested into the `live_flight_states` table.\n",
        "\n",
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# Ensure table_id is correctly set (should be from cell `ea6f4895`)\n",
        "streaming_table_id = f\"{PROJECT_ID}.{BIGQUERY_DATASET}.{BIGQUERY_STREAMING_TABLE}\"\n",
        "\n",
        "print(f\"Checking for data in BigQuery table: {streaming_table_id}\")\n",
        "\n",
        "try:\n",
        "    # Query to get the count of rows and a sample of the latest data\n",
        "    query = f\"\"\"\n",
        "    SELECT *\n",
        "    FROM `{streaming_table_id}`\n",
        "    ORDER BY timestamp DESC\n",
        "    LIMIT 10\n",
        "    \"\"\"\n",
        "    df_stream = client.query(query).to_dataframe()\n",
        "\n",
        "    if not df_stream.empty:\n",
        "        print(f\"‚úÖ Successfully found {len(df_stream)} recent rows in {streaming_table_id}:\")\n",
        "        display(df_stream)\n",
        "\n",
        "        count_query = f\"SELECT COUNT(*) FROM `{streaming_table_id}`\"\n",
        "        count_job = client.query(count_query)\n",
        "        total_rows = list(count_job.result())[0][0]\n",
        "        print(f\"Total rows in {streaming_table_id}: {total_rows}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è No data found in {streaming_table_id} yet. Ensure both Cloud Functions are deployed and running.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"üî¥ An error occurred while querying the streaming table: {e}\")\n",
        "    print(\"Please ensure the BigQuery table exists and the Cloud Functions are correctly configured and deployed.\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for data in BigQuery table: mgmt-467-25259.flights_data.live_flight_states\n",
            "üî¥ An error occurred while querying the streaming table: 404 Not found: Table mgmt-467-25259:flights_data.live_flight_states was not found in location US; reason: notFound, message: Not found: Table mgmt-467-25259:flights_data.live_flight_states was not found in location US\n",
            "\n",
            "Location: US\n",
            "Job ID: c97cb76d-c6da-483b-b1bb-0e42c9880d38\n",
            "\n",
            "Please ensure the BigQuery table exists and the Cloud Functions are correctly configured and deployed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### Cell 8: Data Cleaning and Feature Engineering (Corrected)\n",
        "# @markdown **Objective:** This cell runs a SQL query to create a new, cleaned view of our data. This view will serve as the basis for our machine learning models. We will create a key boolean label, `is_arrival_delayed`, for our classification model.\n",
        "\n",
        "# Define the name for our new view\n",
        "CLEANED_VIEW = \"flights_cleaned\"\n",
        "view_id = f\"{PROJECT_ID}.{BIGQUERY_DATASET}.{CLEANED_VIEW}\"\n",
        "\n",
        "# This SQL query selects relevant columns and creates our new feature.\n",
        "# A VIEW is a virtual table based on the result-set of an SQL statement.\n",
        "# It's a great way to create a clean dataset without duplicating data.\n",
        "# --- FIX: Using the correct column names from the provided schema ---\n",
        "sql_query = f\"\"\"\n",
        "CREATE OR REPLACE VIEW `{view_id}` AS\n",
        "SELECT\n",
        "  -- Construct a DATE type from Year, Month, DayofMonth columns\n",
        "  PARSE_DATE('%Y%m%d', CONCAT(CAST(Year AS STRING), LPAD(CAST(Month AS STRING), 2, '0'), LPAD(CAST(DayofMonth AS STRING), 2, '0'))) AS FL_DATE,\n",
        "  IATA_CODE_Reporting_Airline AS CARRIER,\n",
        "  Origin,\n",
        "  Dest,\n",
        "  DepDelay,\n",
        "  ArrDelay,\n",
        "  Distance,\n",
        "  CAST(DayOfWeek AS STRING) AS DAY_OF_WEEK,\n",
        "  -- Create a boolean label: TRUE if arrival delay is > 15 mins, FALSE otherwise.\n",
        "  -- We also treat NULL delays as not delayed.\n",
        "  CASE\n",
        "    WHEN ArrDelay > 15 THEN TRUE\n",
        "    ELSE FALSE\n",
        "  END AS is_arrival_delayed\n",
        "FROM\n",
        "  `{table_id}`\n",
        "WHERE\n",
        "  -- Filter out cancelled and diverted flights for accurate modeling\n",
        "  Cancelled = 0 AND Diverted = 0;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    # Execute the query to create the view\n",
        "    query_job = client.query(sql_query)\n",
        "    query_job.result() # Wait for the job to complete\n",
        "    print(f\"‚úÖ Successfully created cleaned view: {CLEANED_VIEW}\")\n",
        "\n",
        "    # Verify by showing the first 10 rows of the new view\n",
        "    print(\"\\n--- Sample of Cleaned Data ---\")\n",
        "    df = client.query(f\"SELECT * FROM `{view_id}` LIMIT 10\").to_dataframe()\n",
        "    display(df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"üî¥ An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "MBYom5ZpiOXx",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e717f985-0b72-415c-dd3f-11717da65b3b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî¥ An error occurred: 400 Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.; reason: invalid, location: None.flights_data.live_flight_states, message: Invalid project ID 'None'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.\n",
            "\n",
            "Location: US\n",
            "Job ID: e30baf1e-288c-4986-a632-f5d18ee62c6e\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea6f4895",
        "outputId": "8ce054e9-4632-4e71-8f80-57c31ea24124"
      },
      "source": [
        "# @title ### Define BigQuery Streaming Table\n",
        "# @markdown **Objective:** Create a new BigQuery table specifically designed to receive streaming flight data.\n",
        "# This table will serve as the source for our machine learning models.\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.exceptions import Conflict\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# Define the name for our new streaming BigQuery table\n",
        "BIGQUERY_STREAMING_TABLE = \"live_flight_states\"\n",
        "table_id = f\"{PROJECT_ID}.{BIGQUERY_DATASET}.{BIGQUERY_STREAMING_TABLE}\"\n",
        "\n",
        "# Define the schema for the streaming table\n",
        "# This schema matches the output of the 'publish_flight_data' Cloud Function\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"aircraft_id\", \"STRING\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"callsign\", \"STRING\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"origin_country\", \"STRING\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"timestamp\", \"INTEGER\", mode=\"NULLABLE\"), # Unix timestamp\n",
        "    bigquery.SchemaField(\"longitude\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"latitude\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"velocity_m_s\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "    bigquery.SchemaField(\"baro_altitude_m\", \"FLOAT\", mode=\"NULLABLE\"),\n",
        "]\n",
        "\n",
        "table = bigquery.Table(table_id, schema=schema)\n",
        "\n",
        "try:\n",
        "    # Create the table\n",
        "    table = client.create_table(table)\n",
        "    print(f\"‚úÖ Successfully created streaming BigQuery table: {table.project}.{table.dataset_id}.{table.table_id}\")\n",
        "except Conflict:\n",
        "    print(f\"‚úÖ Streaming BigQuery table '{table_id}' already exists.\")\n",
        "except Exception as e:\n",
        "    print(f\"üî¥ An error occurred while creating the streaming table: {e}\")\n",
        "\n",
        "# Set the global variable 'table_id' to point to this new streaming table\n",
        "# This ensures subsequent ML cells use this table.\n",
        "# It's important to re-run this cell if you restart the kernel,\n",
        "# as the value of `table_id` is crucial for downstream cells.\n",
        "print(f\"'table_id' for downstream ML models is now set to: {table_id}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Successfully created streaming BigQuery table: mgmt-467-25259.flights_data.live_flight_states\n",
            "'table_id' for downstream ML models is now set to: mgmt-467-25259.flights_data.live_flight_states\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57f5b2c8"
      },
      "source": [
        "import functions_framework\n",
        "from google.cloud import bigquery\n",
        "import json\n",
        "import base64\n",
        "import os\n",
        "\n",
        "# --- User-defined BigQuery Dataset and Table --- (ensure these match your created resources)\n",
        "PROJECT_ID = os.environ.get(\"GCP_PROJECT\")\n",
        "BIGQUERY_DATASET = \"flights_data\"\n",
        "BIGQUERY_STREAMING_TABLE = \"live_flight_states\"\n",
        "\n",
        "# Initialize BigQuery client outside the function to reuse across invocations\n",
        "client = bigquery.Client()\n",
        "table_id = f\"{PROJECT_ID}.{BIGQUERY_DATASET}.{BIGQUERY_STREAMING_TABLE}\"\n",
        "\n",
        "@functions_framework.cloud_event\n",
        "def subscribe_and_stream_to_bigquery(cloud_event):\n",
        "    \"\"\"\n",
        "    Cloud Function triggered by a Pub/Sub message.\n",
        "    It parses the message and streams the data into a BigQuery table.\n",
        "    \"\"\"\n",
        "    print(f\"Received CloudEvent: {cloud_event['id']} from {cloud_event['source']}\")\n",
        "    pubsub_message = cloud_event.data\n",
        "\n",
        "    if not pubsub_message:\n",
        "        print(\"No data in Pub/Sub message.\")\n",
        "        return\n",
        "\n",
        "    if 'message' not in pubsub_message:\n",
        "        print(\"Pub/Sub message structure is unexpected. Missing 'message' key.\")\n",
        "        return\n",
        "\n",
        "    if 'data' not in pubsub_message['message']:\n",
        "        print(\"No data payload found in Pub/Sub message.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Decode the Pub/Sub message data (which is base64 encoded)\n",
        "        data = base64.b64decode(pubsub_message['message']['data']).decode('utf-8')\n",
        "        row = json.loads(data)\n",
        "\n",
        "        print(f\"Attempting to stream row to BigQuery: {row}\")\n",
        "\n",
        "        # BigQuery expects a list of rows for insertion\n",
        "        rows_to_insert = [row]\n",
        "\n",
        "        # Stream the row into BigQuery\n",
        "        errors = client.insert_rows_json(table_id, rows_to_insert)\n",
        "\n",
        "        if errors:\n",
        "            print(f\"üî¥ Errors occurred while streaming to BigQuery: {errors}\")\n",
        "        else:\n",
        "            print(f\"‚úÖ Successfully streamed 1 row to {table_id}\")\n",
        "\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"üî¥ Error decoding base64 data: {e}\")\n",
        "        print(f\"Raw message data: {pubsub_message['message']['data']}\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"üî¥ Error parsing JSON payload: {e}\")\n",
        "        print(f\"Decoded string: {data}\")\n",
        "    except Exception as e:\n",
        "        print(f\"üî¥ An unexpected error occurred: {e}\")\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3acb3e1f"
      },
      "source": [
        "### Deployment Instructions for the Pub/Sub to BigQuery Subscriber Cloud Function\n",
        "\n",
        "This Python code, `subscribe_and_stream_to_bigquery`, is designed to be deployed as a Google Cloud Function that reacts to Pub/Sub messages.\n",
        "\n",
        "**To deploy this function, you would typically follow these steps:**\n",
        "\n",
        "1.  **Ensure Pub/Sub Topic Exists:** Make sure your `live-data-stream` Pub/Sub topic exists.\n",
        "\n",
        "2.  **Ensure BigQuery Table Exists:** Confirm that your `live_flight_states` BigQuery table exists with the correct schema (as defined in the previous step).\n",
        "\n",
        "3.  **Save the Code:** Save the Python code above into a file named `main.py`.\n",
        "\n",
        "4.  **Define Dependencies:** Create a `requirements.txt` file in the same directory with the following content:\n",
        "    ```\n",
        "    functions-framework\n",
        "    google-cloud-bigquery\n",
        "    ```\n",
        "\n",
        "5.  **Deploy the Cloud Function:** Use the `gcloud functions deploy` command. You'll need to specify:\n",
        "    *   `--runtime python312` (or your preferred Python version)\n",
        "    *   `--trigger-topic live-data-stream` (this tells the function to subscribe to your Pub/Sub topic)\n",
        "    *   `--entry-point subscribe_and_stream_to_bigquery` (the name of the function to execute)\n",
        "    *   `--region` (e.g., `us-central1`)\n",
        "    *   **Crucially, you need to ensure the Cloud Function's service account has permissions to write to BigQuery.** This typically means the `BigQuery Data Editor` role or a custom role with `bigquery.tables.insertAll` on the target table.\n",
        "\n",
        "    Example deployment command:\n",
        "    ```bash\n",
        "    gcloud functions deploy pubsub-to-bigquery-streamer \\\n",
        "      --runtime python312 \\\n",
        "      --trigger-topic live-data-stream \\\n",
        "      --entry-point subscribe_and_stream_to_bigquery \\\n",
        "      --region us-central1\n",
        "    ```\n",
        "\n",
        "Once deployed, this function will automatically activate and ingest data into your BigQuery table whenever messages are sent to the `live-data-stream` Pub/Sub topic by your first Cloud Function (`publish_flight_data`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### Cell 9: Build, Evaluate, and Predict with a Linear Regression Model\n",
        "# @markdown **Objective:** Use BigQuery ML to create a linear regression model to predict the arrival delay (`ARR_DELAY`).\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.exceptions import NotFound # Import NotFound for specific error handling\n",
        "\n",
        "# Re-initialize the BigQuery client to ensure it's fresh and correctly scoped\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# Re-define necessary variables as they might have been cleared\n",
        "CLEANED_VIEW = \"flights_cleaned\"\n",
        "view_id = f\"{PROJECT_ID}.{BIGQUERY_DATASET}.{CLEANED_VIEW}\"\n",
        "\n",
        "print(f\"Attempting to use view: {view_id}\")\n",
        "\n",
        "# --- Add a check for view existence before proceeding ---\n",
        "try:\n",
        "    client.get_table(view_id) # get_table works for views too\n",
        "    print(f\"‚úÖ BigQuery view '{view_id}' confirmed to exist.\")\n",
        "except NotFound:\n",
        "    print(f\"üî¥ ERROR: BigQuery view '{view_id}' not found. Please ensure Cell 8 (Data Cleaning and Feature Engineering) ran successfully and created the view.\")\n",
        "    raise # Re-raise the error to stop execution if the view is truly not found\n",
        "except Exception as e:\n",
        "    print(f\"üî¥ An unexpected error occurred while checking view existence: {e}\")\n",
        "    raise\n",
        "\n",
        "# --- 1. Create the Linear Regression Model ---\n",
        "print(\"üöÄ Training Linear Regression model...\")\n",
        "create_linear_model_query = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.flight_delay_predictor`\n",
        "OPTIONS(model_type='LINEAR_REG', input_label_cols=['ArrDelay']) AS\n",
        "SELECT\n",
        "  ArrDelay,\n",
        "  DepDelay,\n",
        "  CARRIER,\n",
        "  Distance,\n",
        "  DAY_OF_WEEK\n",
        "FROM\n",
        "  `{view_id}`;\n",
        "\"\"\"\n",
        "linear_job = client.query(create_linear_model_query)\n",
        "linear_job.result()\n",
        "print(\"‚úÖ Linear Regression model created successfully.\")\n",
        "\n",
        "# --- 2. Evaluate the Model ---\n",
        "print(\"\\n--- Model Evaluation ---\")\n",
        "evaluate_linear_model_query = f\"\"\"\n",
        "SELECT * FROM ML.EVALUATE(MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.flight_delay_predictor`);\n",
        "\"\"\"\n",
        "linear_eval_df = client.query(evaluate_linear_model_query).to_dataframe()\n",
        "display(linear_eval_df)\n",
        "\n",
        "# --- 3. Make Predictions with the Model ---\n",
        "print(\"\\n--- Sample Predictions ---\")\n",
        "predict_linear_query = f\"\"\"\n",
        "SELECT\n",
        "  ArrDelay AS actual_delay,\n",
        "  predicted_ArrDelay\n",
        "FROM\n",
        "  ML.PREDICT(MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.flight_delay_predictor`,\n",
        "    (SELECT * FROM `{view_id}` LIMIT 10));\n",
        "\"\"\"\n",
        "linear_predict_df = client.query(predict_linear_query).to_dataframe()\n",
        "display(linear_predict_df)"
      ],
      "metadata": {
        "id": "AW6_4VZVoV4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "outputId": "1429bc74-4736-451a-e39c-e7846e94361a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to use view: None.flights_data.flights_cleaned\n",
            "üî¥ An unexpected error occurred while checking view existence: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/None/datasets/flights_data/tables/flights_cleaned?prettyPrint=false: Invalid resource name projects/None; Project id: None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequest",
          "evalue": "400 GET https://bigquery.googleapis.com/bigquery/v2/projects/None/datasets/flights_data/tables/flights_cleaned?prettyPrint=false: Invalid resource name projects/None; Project id: None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1243510796.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# --- Add a check for view existence before proceeding ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mview_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get_table works for views too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚úÖ BigQuery view '{view_id}' confirmed to exist.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNotFound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mget_table\u001b[0;34m(self, table, retry, timeout)\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mspan_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m         api_response = self._call_api(\n\u001b[0m\u001b[1;32m   1211\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0mspan_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BigQuery.getTable\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             ):\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequest\u001b[0m: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/None/datasets/flights_data/tables/flights_cleaned?prettyPrint=false: Invalid resource name projects/None; Project id: None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### Cell 10: Build, Evaluate, and Predict with a Logistic Regression Model\n",
        "# @markdown **Objective:** Use BigQuery ML to create a logistic regression model to predict if a flight will be significantly delayed (`is_arrival_delayed`).\n",
        "\n",
        "# --- 1. Create the Logistic Regression Model ---\n",
        "print(\"üöÄ Training Logistic Regression model...\")\n",
        "create_logistic_model_query = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.flight_delay_classifier`\n",
        "OPTIONS(model_type='LOGISTIC_REG', input_label_cols=['is_arrival_delayed']) AS\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  `{view_id}`;\n",
        "\"\"\"\n",
        "logistic_job = client.query(create_logistic_model_query)\n",
        "logistic_job.result()\n",
        "print(\"‚úÖ Logistic Regression model created successfully.\")\n",
        "\n",
        "# --- 2. Evaluate the Model ---\n",
        "print(\"\\n--- Model Evaluation ---\")\n",
        "evaluate_logistic_model_query = f\"\"\"\n",
        "SELECT * FROM ML.EVALUATE(MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.flight_delay_classifier`);\n",
        "\"\"\"\n",
        "logistic_eval_df = client.query(evaluate_logistic_model_query).to_dataframe()\n",
        "display(logistic_eval_df)\n",
        "\n",
        "# --- 3. Make Predictions with the Model ---\n",
        "print(\"\\n--- Sample Predictions ---\")\n",
        "# --- FIX: Changed 'prob' to the correct column name 'predicted_is_arrival_delayed_probs' ---\n",
        "predict_logistic_query = f\"\"\"\n",
        "SELECT\n",
        "  is_arrival_delayed AS actual_is_delayed,\n",
        "  predicted_is_arrival_delayed,\n",
        "  predicted_is_arrival_delayed_probs\n",
        "FROM\n",
        "  ML.PREDICT(MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.flight_delay_classifier`,\n",
        "    (SELECT * FROM `{view_id}` LIMIT 10))\n",
        "\"\"\"\n",
        "logistic_predict_df = client.query(predict_logistic_query).to_dataframe()\n",
        "display(logistic_predict_df)"
      ],
      "metadata": {
        "id": "dcNfV9ekos-9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "ec577e3c-8098-4df7-de8f-0133f7fb4451"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Training Logistic Regression model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFound",
          "evalue": "404 POST https://bigquery.googleapis.com/bigquery/v2/projects//jobs?prettyPrint=false: Request couldn't be served.\n\nLocation: None\nJob ID: fa92a489-1f4c-43a9-a5ef-bcc739ea1b53\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2186066799.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mview_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlogistic_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_logistic_model_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mlogistic_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Logistic Regression model created successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[1;32m   3571\u001b[0m             )\n\u001b[1;32m   3572\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mapi_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0menums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryApiMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINSERT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3573\u001b[0;31m             return _job_helpers.query_jobs_insert(\n\u001b[0m\u001b[1;32m   3574\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3575\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_job_helpers.py\u001b[0m in \u001b[0;36mquery_jobs_insert\u001b[0;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, callback)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mdo_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DEFAULT_QUERY_JOB_INSERT_RETRY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;31m# The future might be in a failed state now, but if it's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_job_helpers.py\u001b[0m in \u001b[0;36mdo_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mjob_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 callback(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleAPICallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m             exc.message = _EXCEPTION_FOOTER_TEMPLATE.format(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/base.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;31m# job has an ID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mspan_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         api_response = client._call_api(\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mspan_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BigQuery.job.begin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             ):\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFound\u001b[0m: 404 POST https://bigquery.googleapis.com/bigquery/v2/projects//jobs?prettyPrint=false: Request couldn't be served.\n\nLocation: None\nJob ID: fa92a489-1f4c-43a9-a5ef-bcc739ea1b53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### Cell 11: Build and Analyze a K-Means Clustering Model\n",
        "# @markdown **Objective:** Use BigQuery ML's K-Means to group flights into distinct clusters based on their characteristics.\n",
        "\n",
        "# --- 1. Create the K-Means Clustering Model ---\n",
        "print(\"üöÄ Training K-Means Clustering model...\")\n",
        "create_kmeans_model_query = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.flight_clusterer`\n",
        "OPTIONS(model_type='KMEANS', num_clusters=5) AS\n",
        "SELECT\n",
        "  DepDelay,\n",
        "  ArrDelay,\n",
        "  Distance\n",
        "FROM\n",
        "  `{view_id}`\n",
        "WHERE DepDelay IS NOT NULL AND ArrDelay IS NOT NULL;\n",
        "\"\"\"\n",
        "kmeans_job = client.query(create_kmeans_model_query)\n",
        "kmeans_job.result()\n",
        "print(\"‚úÖ K-Means Clustering model created successfully.\")\n",
        "\n",
        "# --- 2. Analyze the Cluster Centroids ---\n",
        "print(\"\\n--- Cluster Centroid Analysis ---\")\n",
        "# ML.CENTROIDS shows the average values for each feature within each cluster.\n",
        "# This helps us understand what defines each cluster (e.g., Cluster 1 is short-haul flights with minor delays).\n",
        "analyze_centroids_query = f\"\"\"\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.CENTROIDS(MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.flight_clusterer`);\n",
        "\"\"\"\n",
        "centroids_df = client.query(analyze_centroids_query).to_dataframe()\n",
        "display(centroids_df)\n",
        "\n",
        "# --- 3. See which Cluster Each Flight Belongs To ---\n",
        "print(\"\\n--- Sample Cluster Assignments ---\")\n",
        "predict_kmeans_query = f\"\"\"\n",
        "SELECT\n",
        "  CENTROID_ID,\n",
        "  DepDelay,\n",
        "  ArrDelay,\n",
        "  Distance\n",
        "FROM\n",
        "  ML.PREDICT(MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.flight_clusterer`,\n",
        "    (SELECT * FROM `{view_id}` LIMIT 10));\n",
        "\"\"\"\n",
        "kmeans_predict_df = client.query(predict_kmeans_query).to_dataframe()\n",
        "display(kmeans_predict_df)"
      ],
      "metadata": {
        "id": "PgBj8MJJpMbh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "cb809310-ed07-4cca-c1d1-80886fd1c440"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Training K-Means Clustering model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFound",
          "evalue": "404 POST https://bigquery.googleapis.com/bigquery/v2/projects//jobs?prettyPrint=false: Request couldn't be served.\n\nLocation: None\nJob ID: 8251efdb-7c7b-466f-b438-f1d3db3c38e6\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2829599799.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mWHERE\u001b[0m \u001b[0mDepDelay\u001b[0m \u001b[0mIS\u001b[0m \u001b[0mNOT\u001b[0m \u001b[0mNULL\u001b[0m \u001b[0mAND\u001b[0m \u001b[0mArrDelay\u001b[0m \u001b[0mIS\u001b[0m \u001b[0mNOT\u001b[0m \u001b[0mNULL\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \"\"\"\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mkmeans_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_kmeans_model_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mkmeans_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ K-Means Clustering model created successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[1;32m   3571\u001b[0m             )\n\u001b[1;32m   3572\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mapi_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0menums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryApiMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINSERT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3573\u001b[0;31m             return _job_helpers.query_jobs_insert(\n\u001b[0m\u001b[1;32m   3574\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3575\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_job_helpers.py\u001b[0m in \u001b[0;36mquery_jobs_insert\u001b[0;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, callback)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mdo_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DEFAULT_QUERY_JOB_INSERT_RETRY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;31m# The future might be in a failed state now, but if it's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_job_helpers.py\u001b[0m in \u001b[0;36mdo_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mjob_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 callback(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleAPICallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m             exc.message = _EXCEPTION_FOOTER_TEMPLATE.format(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/base.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;31m# job has an ID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mspan_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         api_response = client._call_api(\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mspan_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BigQuery.job.begin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             ):\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFound\u001b[0m: 404 POST https://bigquery.googleapis.com/bigquery/v2/projects//jobs?prettyPrint=false: Request couldn't be served.\n\nLocation: None\nJob ID: 8251efdb-7c7b-466f-b438-f1d3db3c38e6\n"
          ]
        }
      ]
    }
  ]
}